{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"DMM's Technical Documentation","text":"","path":["DMM's Technical Documentation"],"tags":[]},{"location":"inacawo/","level":1,"title":"InaCAWO","text":"<p>InaCAWO, stands for Indonesia Coupled Atmosphere Wave Ocean, is a state-of-the art high-resolution numerical modelling to support marine weather services in Indonesia Archipelago.</p> <p>Let's dive down into the following sections:</p> <ul> <li>Overview</li> <li>Configurations</li> <li>Operational Flow<ul> <li>Production</li> <li>Dissemination</li> <li>Troubleshooting</li> </ul> </li> <li>Tutorial<ul> <li>Installation</li> <li>Forecast Mode</li> <li>Hindcast Mode</li> </ul> </li> </ul>","path":["InaCAWO"],"tags":[]},{"location":"inacawo/operational/","level":1,"title":"Operational Flow","text":"<p>work in progress</p>","path":["InaCAWO","Operational Flow"],"tags":[]},{"location":"inacawo/operational/dissemination/","level":1,"title":"Dissemination","text":"<p>work in progress</p>","path":["InaCAWO","Operational Flow","Dissemination"],"tags":[]},{"location":"inacawo/operational/production/","level":1,"title":"Production","text":"<p>work in progress</p>","path":["InaCAWO","Operational Flow","Production"],"tags":[]},{"location":"inacawo/operational/troubleshooting/","level":1,"title":"Troubleshooting","text":"<p>work in progress</p>","path":["InaCAWO","Operational Flow","Troubleshooting"],"tags":[]},{"location":"inacawo/overview/","level":1,"title":"Overview","text":"<p>BMKG previously operated independent atmospheric, wave, and ocean models, which limited the representation of cross-domain interactions in forecast outputs. To address this limitation, BMKG has implemented InaCAWO, a three-way coupled atmosphere-wave-ocean modeling system.</p> <p>InaCAWO provides significantly higher spatial resolution and improved physical coupling between model components, enabling more accurate simulation of complex air-sea processes.</p> <p>The system enhances forecast accuracy and spatial localization, supporting more reliable early warning and decision-making for severe weather and marine hazards.</p> <p>Go to the Configurations page for detailed information.</p>","path":["InaCAWO","Overview"],"tags":[]},{"location":"inacawo/overview/configuration/","level":1,"title":"Configurations","text":"","path":["InaCAWO","Overview","Configurations"],"tags":[]},{"location":"inacawo/overview/configuration/#models-components","level":2,"title":"Model's Components","text":"<p>At its core, InaCAWO consists of three numerical models, e.g. WRF (Weather Research and Forecasting), SWAN (Simulating Wave Nearshore), and ROMS (Regional Ocean Modelling System). The 3-way coupled forecast system is presently fully operational running the COAWST (Coupled-Ocean-Atmosphere-Wave-Sediment Transport) Modeling System on the BKMG HPC.</p> <p>During the parallel execution, InaCAWO allows the direct exchange of critical metocean surface data between the models (shown in Figure 1 below). That is, each model is “aware of” and concurrently responds to the other models, much as these processes occur in nature. This is done through a Model Coupling Toolkit (MCT). </p> Figure 1. InaCAWO Diagram of Standalone model.","path":["InaCAWO","Overview","Configurations"],"tags":[]},{"location":"inacawo/overview/configuration/#geographical-extent-and-grid-spacing","level":2,"title":"Geographical Extent and Grid Spacing","text":"<p>A high-resolution (0.25deg, approximately 3-km) is covering Indonesia region (90-145E &amp; 15S-15N) serve as the domain of the InaCAWO model. Within this domain, there are 1130 latitudinal “rows” and 2040 longitudinal “columns” that constitute a single 2D slice of the domain, amounting to 2,305,000 compute points per 2 dimensional (2D) slab per variable. </p> Figure 2. InaCAWO Domain. <p>There are 70-vertical sigma layers in the ocean (ROMS) component, and 48 atmospheric WRF layers. Since the SWAN wave model is 2D in spectral-space, it's additional “layers” are defined by the spectral truncation needed to resolve wind-driven and swell-driven components at the 3km spatial scale.  This means that at minimum, the number of compute points per prognostic state variable (combining ocean and atmosphere) amounts to ~(48+70+1)* 2,305,000 == 274,318,800, each of which must be solved at a computational timestep small enough to prevent numerical instability based on the well-known CFL requirement (as applied separately to ocean and atmosphere).  </p>","path":["InaCAWO","Overview","Configurations"],"tags":[]},{"location":"inacawo/overview/configuration/#input-data","level":2,"title":"Input Data","text":"<p>work in progress</p>","path":["InaCAWO","Overview","Configurations"],"tags":[]},{"location":"inacawo/overview/configuration/#supporting-tools","level":2,"title":"Supporting Tools","text":"<p>work in progress</p>","path":["InaCAWO","Overview","Configurations"],"tags":[]},{"location":"inacawo/overview/configuration/#computational-resources-usage","level":2,"title":"Computational Resources Usage","text":"<p>work in progress</p>","path":["InaCAWO","Overview","Configurations"],"tags":[]},{"location":"inacawo/tutorial/","level":1,"title":"Tutorial","text":"<p>In this section, you'll find tutorial to run InaCAWO in two different scenarios, e.g. Forecast and Hindcast Mode.</p> <p>Warning</p> <p>The hands-on in this section is intended for internal BMKG users, non-BMKG users may still be able to follow the tutorial without access to the computational resources.</p> <p>Info</p> <p>Please contact the team for further information at produksi.maritim@bmkg.go.id.</p>","path":["InaCAWO","Tutorial"],"tags":[]},{"location":"inacawo/tutorial/forecast/","level":1,"title":"Forecast Mode","text":"<p>Warning</p> <p>The hands-on in this section is intended for internal BMKG users, non-BMKG users may still be able to follow the tutorial without access to the computational resources.</p> <p>Info</p> <p>Please contact the team for further information at produksi.maritim@bmkg.go.id.</p> <p>work in progress</p>","path":["InaCAWO","Tutorial","Forecast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/","level":1,"title":"Hindcast Mode","text":"<p>Warning</p> <p>The hands-on in this section is intended for internal BMKG users, non-BMKG users may still be able to follow the tutorial without access to the computational resources.</p> <p>Info</p> <p>This hands-on tutorial is designed to run on the MDC Supercomputer using the <code>cawohdcst_ft2</code> user account.</p> <p>Please contact the team for further information at produksi.maritim@bmkg.go.id.</p> Contents ...","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#contents","level":3,"title":"Contents","text":"<ul> <li> <p>Main differences from the forecast system</p> <ul> <li>Preprocessing Workflow</li> <li>Physical Considerations</li> </ul> </li> <li> <p>General Workflow</p> </li> <li> <p>Configurations</p> </li> <li> <p>Dependencies</p> <ul> <li>Conda Environment</li> <li>LiveOcean</li> </ul> </li> <li> <p>Preparing The Working Directory</p> </li> <li> <p>Global Reanalysis Data Acquisition</p> <ul> <li>ERA5 Atmospheric Data</li> <li>ERA5 Waves Data</li> <li>Mercator GLORYS12V1 Data</li> </ul> </li> <li> <p>Pre Processing</p> <ul> <li>WRF Forcing Files</li> <li>SWAN Forcing Files</li> <li>ROMS Forcing Files</li> </ul> </li> <li> <p>Running The Hindcast</p> <ul> <li>Compiling COAWST</li> <li>Running Scheme</li> <li>Modifying Namelist Files</li> <li>Copying input files</li> <li>Running a day cycle</li> <li>Running automation</li> </ul> </li> <li> <p>Post Processing</p> <ul> <li>WRF2D</li> <li>WRF3D</li> <li>Ocean2D</li> <li>Ocean3D</li> </ul> </li> <li> <p>Summary and Common Problems</p> </li> </ul>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#main-differences-from-the-forecast-system","level":2,"title":"Main differences from the forecast system","text":"","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#preprocessing-workflow","level":3,"title":"Preprocessing workflow","text":"<p>The forecast input data is available only near each forecast cycle time. Thus, the data must be downloaded and processed as soon as possible so that the forecast outputs are generated in a timely manner.</p> <p>To automate this process and ensure the results are delivered within the required time frame, the forecast system relies heavily on ROME tools. This suite of tools consists of complex driver scripts and watchdogs that manage each step of the workflow.</p> <p>Although the hindcast workflow is based on the same processes used in the operational forecasts, it is greatly simplified because all input data for the 30-year period is already available. The hindcast components can run independently: while the hindcast is advancing through a given day, the reanalysis downloads and forcing-file generation can proceed for future dates. Likewise, postprocessing and model–data comparisons can be performed for earlier periods once their hindcast cycles have finished.</p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#physical-considerations","level":3,"title":"Physical Considerations","text":"<p>The model configurations remain essentially the same, with one major exception: the ROMS open boundary conditions (OBCs).</p> <p>In the forecast system, the velocities use zero-gradient boundary conditions, meaning the model does not ingest external information and simply extrapolates interior values to the boundary. This approach is acceptable for forecasts because each cycle spans only 10 days. However, in a long-term simulation the internal velocity fields will gradually drift away from realistic conditions. To address this, the hindcast uses radiation + nudging OBCs for the velocities.</p> <p>For long simulations, it is also recommended to apply a light nudging zone near the boundaries, consistent with the sponge-layer (Marchesiello et al., 2003). Accordingly, a climatology nudging was applied to the four grid points closest to each boundary. The nudging was applied to temperature, salinity, baroclinic and barotropic velocities, and sea surface height, all obtained from the Glorys Reanalysis.</p> <p>Additionally, the boundary conditions for SSH and barotropic velocities were updated to the Flather–Chapman combination, which is known to be very stable when used together with the OBC options noted above.</p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#general-workflow","level":2,"title":"General Workflow","text":"<pre><code>flowchart TD\n\nA@{ shape: circle, label: \"Start\" } \n--&gt; B{Check conda envs}\nB -- Not available --&gt; C[Install conda and create environment]\nC --&gt; B\nB -- Available --&gt; E[Download Global Data]\n\nsubgraph PreProcessing\n    E --&gt; F@{ shape: lean-r, label: \"Global data from ERA5 Atm, ERA5 Wave, and GLORYS Mercator Ocean\" }\n    F --&gt; G[Generate Forcing Files]\n    G --&gt; H@{ shape: lean-r, label: \"Forcing Files for WRF, SWAN, ROMS\" }\nend\n\nsubgraph MainProcessing\n    I{Running Hindcast}\n    I -- Running Day 1 --&gt; J[Compile COAWST with Ramp Tides] --&gt; K@{ shape: lean-r, label: \"Binary CoawstM\" }\n    I -- Running after Day 1 --&gt; L[Compile COAWST without Ramp Tides] --&gt; M@{ shape: lean-r, label: \"Binary CoawstM\"}\n\n    N@{ shape: lean-r, label: \"Edited namelist files for WRF, SWAN, ROMS, and COAWST\"}\n\n    O[Model integration]\n\n    K --&gt; P@{ shape: circle, label: \"OR\" } \n    M --&gt; P@{ shape: circle, label: \"OR\" } \n    P --&gt; O\n    N --&gt; O\n    H --&gt; O\n    O --&gt; Q@{ shape: lean-r, label: \"Raw Output\" }\nend\n\nsubgraph PostProcessing\n    Q --&gt; R[PostProcessing]\n    R --&gt; S@{shape: lean-r, label: \"Processed output\"}\nend\n\nS --&gt; T@{shape: circle, label: \"End\"}\n\nPreProcessing --&gt; MainProcessing --&gt; PostProcessing</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#configurations","level":2,"title":"Configurations","text":"Model - COAWSTDomain and ResolutionStatic InputDynamic Input <ul> <li>WRF </li> <li>ROMS</li> <li>SWAN</li> </ul> <ul> <li>15S to 15N, 90E to 145E</li> <li>~3km</li> </ul> <ul> <li>Land-Use/Land-Cover: Friedl and Sulla-Menashe (2015)</li> <li>Soils texture: Dy and Fung (2016)</li> <li>Terrain: GMTED2010</li> <li>Coastal boundaries: GSHHG (Wessel and Smith, 1996)</li> <li>Climatological River Discharge: Global Data Runoff Center or Global Annual River Discharge Dataset</li> <li>Bathymetry: GEBCO 2021 (~450m)</li> <li>Tides: TPXO (Egbert and Erofeeva, 2002)</li> </ul> <ul> <li>Atmosphere (surface and pressure levels): ECMWF ERA5</li> <li>Ocean: Mercator reanalyses GLORYS12V2.1</li> <li>Waves: ECMWF ERA5 Waves</li> </ul>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#dependencies","level":2,"title":"Dependencies","text":"","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#conda-environment","level":3,"title":"Conda Environment","text":"<p>Downloading, preprocessing, and postprocessing scripts are based on python tools. To ensure reproducibility of the processes, conda environments should be created and activated previously.</p> <p>In <code>cawohdcst_ft2</code> home directory, <code>conda</code>'s source code is available in <code>/home/cawohdcst_ft2/opt/miniforge3</code>.</p> <p><code>conda</code> is intentionally not activated by default (to avoid cluttering <code>.bashrc</code>) in order to keep working environment clean. Hence, you need to activate it by typing the following command.</p> <pre><code>source /home/cawohdcst_ft2/opt/miniforge3/etc/profile.d/conda.sh\nconda activate\n</code></pre> Validating conda <p>You should see the output like this if you type <code>conda info</code> <pre><code>(base) [cawohdcst_ft2@mdclogin1 ~]$ conda info\n\n    active environment : base\n    active env location : /home/cawohdcst_ft2/opt/miniforge3\n            shell level : 1\n    user config file : /home/cawohdcst_ft2/.condarc\npopulated config files : /home/cawohdcst_ft2/opt/miniforge3/.condarc\n        conda version : 25.11.0\n    conda-build version : not installed\n        python version : 3.12.12.final.0\n                solver : libmamba (default)\n    virtual packages : __archspec=1=zen2\n                        __conda=25.11.0=0\n                        __cuda=0=0\n                        __glibc=2.28=0\n                        __linux=4.18.0=0\n                        __unix=0=0\n    base environment : /home/cawohdcst_ft2/opt/miniforge3  (writable)\n    conda av data dir : /home/cawohdcst_ft2/opt/miniforge3/etc/conda\nconda av metadata url : None\n        channel URLs : https://conda.anaconda.org/conda-forge/linux-64\n                        https://conda.anaconda.org/conda-forge/noarch\n        package cache : /home/cawohdcst_ft2/opt/miniforge3/pkgs\n                        /home/cawohdcst_ft2/.conda/pkgs\n    envs directories : /home/cawohdcst_ft2/opt/miniforge3/envs\n                        /home/cawohdcst_ft2/.conda/envs\n            platform : linux-64\n            user-agent : conda/25.11.0 requests/2.32.5 CPython/3.12.12 Linux/4.18.0-348.23.1.el8_5.x86_64 rhel/8.5 glibc/2.28 solver/libmamba conda-libmamba-solver/25.11.0 libmambapy/2.4.0\n                UID:GID : 10064:10023\n            netrc file : None\n        offline mode : False\n</code></pre></p> <p>There are four environments created for preprocessing and postprocessing.</p> <ol> <li><code>cawo_post</code>: postprocessing</li> <li><code>cdsapi</code>: downloading ERA5 data</li> <li><code>copernicusmarine</code>: downloading MERCATOR/CMEMS data</li> <li><code>loenv</code>: preprocessing ROMS</li> </ol> <p>The modules required for each environment are stored in a <code>yaml</code> file, located in <code>/home/cawohdcst_ft2/yml_files</code>. These <code>yaml</code> files can be used for creating the intended environment if you want play around in your own computer.</p> Checking conda environments <pre><code>(base) [cawohdcst_ft2@mdclogin1 ~]$ conda env list\n\n# conda environments:\n#\n# * -&gt; active\n# + -&gt; frozen\nbase                 *   /home/cawohdcst_ft2/opt/miniforge3\ncawo_post                /home/cawohdcst_ft2/opt/miniforge3/envs/cawo_post\ncdsapi                   /home/cawohdcst_ft2/opt/miniforge3/envs/cdsapi\ncopernicusmarine         /home/cawohdcst_ft2/opt/miniforge3/envs/copernicusmarine\nloenv                    /home/cawohdcst_ft2/opt/miniforge3/envs/loenv\n\n(base) [cawohdcst_ft2@mdclogin1 ~]$ \n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#liveocean","level":3,"title":"LiveOcean","text":"<p>LiveOcean(LO) is used for ROMS preprocessing tool. It was customized by CLSBrasil team, so we will use the source code from <code>/scratch/cawohdcst_ft/home/cawohdcst/LO</code>. Luckily, you don't have to do that as it already exists in the <code>cawohdcst_ft2</code> home directory.</p> How to create LiveOcean environment? <p>In order to install this tool, we need to retrieve the source code, either from github or the one that exists in <code>cawohdcst_ft2</code> home directory. Inside the <code>LO</code> directory, there is a <code>yaml</code> file containing all modules necessary to run <code>lo_tools</code>. Hence, the way to go there is pretty simple, we only need to execute a well-known <code>conda</code> command to create environment from <code>yaml</code> file. <pre><code>conda create -f loenv.yml\n</code></pre></p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#preparing-the-working-directory","level":2,"title":"Preparing The Working Directory","text":"<p>This hands-on assume that participants logged in to MDC Supercomputer via <code>cawohdcst_ft2</code> user account. Therefore, each user must define their own working directory. </p> <p>Please create directory in the <code>cawohdcst_ft2</code> home directory using an appropriate name of your choice (not too long and without space). All downloading, preprocessing (except the LO source code) and postprocessing scripts should be stored in this directory to avoid editing the same files across different participants. Additionally you also need to create directory in <code>/scratch</code> same as in <code>/home/cawohdcst_ft2</code> to store the data. </p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#modifying-envsh","level":3,"title":"Modifying <code>env.sh</code>","text":"<p>It is mandatory setup our working environment using <code>env.sh</code>. Please copy the file from <code>/home/cawohdcst_ft2/hindcast_scripts/env.sh</code> to your working directory. Here is the sample.</p> <pre><code>[cawohdcst_ft2@mdclogin1 tyo]$ pwd\n/home/cawohdcst_ft2/tyo\n[cawohdcst_ft2@mdclogin1 tyo]$ cp /home/cawohdcst_ft2/hindcast_scripts/env.sh .\n[cawohdcst_ft2@mdclogin1 tyo]$\n</code></pre> <p>Edit the <code>CAWO_HINDCAST_BASE</code> in <code>env.sh</code> file as per your <code>scratch</code> directory.</p> Click here to view the full script env.sh<pre><code>#!/bin/bash\n# \n# Working directory\n# \nexport CAWO_HINDCAST_BASE='/scratch/cawohdcst_ft2/tyo/cawo_hindcast'\n#\n# --------------------\n# Global Data Download\n# --------------------\nexport CAWO_INPUT=$CAWO_HINDCAST_BASE'/cawo_input'\n# --------------\n# Preprocessing\n# --------------\nexport WPS_DIR='/scratch/cawohdcst_ft2/data/wps_run'\nexport WPS_STATIC_DIR='/scratch/cawohdcst_ft/data/static/wps/wps-4.3.1_static'\nexport WRF_DIR='/scratch/cawohdcst_ft/data/static/wrf'\nexport WRF_STATIC_DIR=$WRF_DIR'/wrf-4.3.1_static'\nexport WRF_STATIC_EXTRA_DIR=$WRF_DIR'/extra_static'\nexport GEOGRID_FILE='/scratch/cawohdcst_ft/data/wps_run/geogrid_v43/geo_em.d01.nc.ID03F3'\nexport GRID_DATA='/scratch/cawohdcst_ft2/data/grids'\nexport ERA5_BASE_DIR=$CAWO_INPUT'/era5'\nexport GLORYS_BASE_DIR=$CAWO_INPUT'/mercator'\nexport ROMS_FORCING='/scratch/cawohdcst_ft2/data/roms_forcing' # tied to loenv, which defined at the conda env creation.\n# export ROMS_FORCING=$CAWO_INPUT'/roms_forcing' # ini bisa dipakai dengan mengubah Lfun dkk diimport dari utils instead dari installed lo_tools pada file driver_forcing3.py, tapi prosesnya tidak menghasilkan results.txt di LO_output, meski output data nc-ya tergenerate di folder yang didefine di line ini. \n#\n# LiveOcean\n# export LO_Output=$DATA_DIR'/LO_output'\n# export LO_User=$DATA_DIR'/LO_output'\n#\n# -----------------\n# Model integration\n# -----------------\nexport CAWO_HINDCAST_RUN=$CAWO_HINDCAST_BASE'/cawo_hindcast_run'\n# --------------\n# Postprocessing\n# --------------\nexport CAWO_OUTPUT=$CAWO_HINDCAST_BASE'/cawo_output'\n</code></pre> <p>Then <code>source</code> it. <pre><code>source env.sh\n</code></pre></p> Click here to see the sample structure of the working directory <pre><code>[cawohdcst_ft2@mdclogin1 tyo]$ pwd\n/home/cawohdcst_ft2/tyo\n[cawohdcst_ft2@mdclogin1 tyo]$ tree\n.\n├── env.sh\n├── mainprocess\n├── postprocess\n└── preprocess\n    ├── get_era5\n    │   ├── get_era5_pl_automate.py\n    │   ├── get_era5_surface_automate.py\n    │   └── get_era5_waves.py\n    ├── get_glorys\n    │   ├── get_glorys_reanalysis_interim.py\n    │   └── get_glorys_reanalysis.py\n    ├── get_swan_bry\n    │   ├── make_swan_bc.py\n    │   └── slurm_make_swan_bc.bash\n    └── wps_run\n        ├── slurm_run_metgrid.bash\n        ├── slurm_run_real.bash\n        └── slurm_run_ungrib.bash\n\n7 directories, 11 files\n[cawohdcst_ft2@mdclogin1 tyo]$ mkdir /scratch/cawohdcst_ft2/tyo/\n[cawohdcst_ft2@mdclogin1 tyo]$ /scratch/cawohdcst_ft2/tyo/\n-sh: /scratch/cawohdcst_ft2/tyo/: Is a directory\n[cawohdcst_ft2@mdclogin1 tyo]$ \n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#global-reanalysis-data-acquisition","level":2,"title":"Global Reanalysis Data Acquisition","text":"<p>To generate all the input files that are necessary to run the hindcast, global reanalysis data that are used as initial and boundary conditions need to be downloaded to cover the total period of simulation. This procedure doesn't need to be complete before the simulations start, but needs to be always ahead in time in respect from the simulation. </p> <p>The hindcast daily cycles start at 12h00 UTC each day. This is determined by the Glorys Reanalysis time which are daily means centered at 12h UTC. Thus, to facilitate the workflow for the generation of forcing files for each day, the global models data are also downloaded for each daily cycle starting at 12h00 UTC.</p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#era5-atmospheric-data","level":3,"title":"ERA5 Atmospheric Data","text":"<p>The ECMWF ERA5 data can be downloaded using the ECMWF Climate Data Store API (CDSAPI). The <code>.cdsapirc</code> already configured in <code>cawohdcst_ft2</code> home directory, so you don't need to worry about this.</p> Click to see detailed parameters 3D Data2D Data <p>Pressure levels: 1000, 950, 925, 900, 850, 800, 700, 600, 500, 400, 300, 250, 200, 150, 100, 70, 50, 30, 20, 10, 7, 5</p> ECMWF Parameter Code GRIB Parameter Name Name Units 129 GH Geopotential Height m 130 TT Temperature K 131 UU U component of Wind Velocity m/s 132 VV V component of Wind Velocity m/s 157 RH Relative Humidity % ECMWF GRIB Parameter Code Parameter Name Name Units 165 10U U component of the wind velocity m/s 166 10V V component of the wind velocity m/s 167 2T 2 m Temperature K 168 2D 2 m Dewpoint Temperature K 172 LSM Land-Sea Mask 0/1 flag 134 SP Surface Pressure Pa 151 MSL Mean Sea-Level Pressure Pa 235 SKT Skin Temperature K 31 CI Sea Ice Fraction fraction 34 SST Sea Surface Temperature K 33 RSN Snow Density kg/m³ 141 SD Snow Depth m (water equivalent) 139 STL1 Soil Temperature 0–7 cm K 170 STL2 Soil Temperature 7–28 cm K 183 STL3 Soil Temperature 28–100 cm K 236 STL4 Soil Temperature 100–255 cm K 39 SWVL1 Soil Moisture 0–7 cm m³/m³ 40 SWVL2 Soil Moisture 7–28 cm m³/m³ 41 SWVL3 Soil Moisture 28–100 cm m³/m³ 42 SWVL4 Soil Moisture 100–255 cm m³/m³ <p>The required variables from ERA5 are downloaded using the ECMWF CDS api and python sripts:</p> <ul> <li>3D data download script: <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/get_era5/get_era5_pl_automate.py</code></li> <li>2D data download script: <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/get_era5/get_era5_surface_automate.py</code></li> </ul> <p>Now, copy these files to your working directory.  <pre><code>[cawohdcst_ft2@mdclogin1 preprocess]$ pwd\n/home/cawohdcst_ft2/tyo/preprocess\n[cawohdcst_ft2@mdclogin1 preprocess]$ cp -r /home/cawohdcst_ft2/hindcast_scripts/preprocess/get_era5\n[cawohdcst_ft2@mdclogin1 preprocess]$ ls get_era5/ -l\ntotal 12\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 2697 Jan 23 07:41 get_era5_pl_automate.py\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 2907 Jan 23 07:41 get_era5_surface_automate.py\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 2476 Jan 23 07:41 get_era5_waves.py\n[cawohdcst_ft2@mdclogin1 preprocess]$ \n</code></pre></p> <p>Adjust the dates (lines 6 &amp; 7) and <code>folder_name</code> (line 40) in both <code>*.py</code> files.</p> <p> get_era5_pl_automate.py<pre><code>...\n...\n5 # Define the range of dates to process\n6 start_date = datetime(1995, 1, 1) # Adjust this\n7 end_date = datetime(1995, 1, 5)  # Adjust this, example: 2 days; adjust as needed\n...\n...\n28 current_date = start_date\n29 while current_date &lt;= end_date:\n...\n...\n39     # Create output directory\n40     folder_name = f\"/scratch/cawohdcst_ft2/tyo/data/era5/era5_{current_date.strftime('%Y%m%d')}\"\n41     os.makedirs(folder_name, exist_ok=True)\n42 \n...\n...\n</code></pre></p> <p>The <code>*.grib</code> files are from the day represented in the folder names starting at 12h00 UTC until the next day 12h00 UTC.</p> Click here to view the execution log. 3D Data2D Data <pre><code>2026-01-23 04:34:56,410 INFO Request ID is 40f2233a-4641-4f97-b6e1-5d9dd765e82c\n2026-01-23 04:34:56,588 INFO status has been updated to accepted\n2026-01-23 04:35:10,769 INFO status has been updated to running\n2026-01-23 04:36:51,885 INFO status has been updated to successful\nDownloading /scratch/cawohdcst_ft2/tyo/data/era5/era5_19950104/part2.grib\n2026-01-23 04:37:06,470 INFO Request ID is a36f93bf-e1ea-4de4-83f9-d6f327e81dba\n2026-01-23 04:37:06,743 INFO status has been updated to accepted\n2026-01-23 04:37:15,596 INFO status has been updated to running\n2026-01-23 04:39:02,081 INFO status has been updated to successful\nDownloading /scratch/cawohdcst_ft2/tyo/data/era5/era5_19950105/part1.grib\n{'area': [15.5, 89.5, -15.5, 145.5],\n'data_format': 'grib',\n'day': '05',\n'month': '01',\n'pressure_level': ['5',\n                    '7',\n                    '10',\n                    '20',\n                    '30',\n                    '50',\n                    '70',\n                    '100',\n                    '150',\n                    '200',\n                    '250',\n                    '300',\n                    '400',\n                    '500',\n                    '600',\n                    '700',\n                    '800',\n                    '850',\n                    '900',\n                    '925',\n                    '950',\n                    '1000'],\n'product_type': 'reanalysis',\n'time': ['12:00',\n        '13:00',\n        '14:00',\n        '15:00',\n        '16:00',\n        '17:00',\n        '18:00',\n        '19:00',\n        '20:00',\n        '21:00',\n        '22:00',\n        '23:00'],\n'variable': ['geopotential',\n            'relative_humidity',\n            'temperature',\n            'u_component_of_wind',\n            'v_component_of_wind'],\n'year': '1995'}\n2026-01-23 04:39:29,148 INFO Request ID is b157c67d-319a-48a2-aaf6-af1fa1bcde60\n2026-01-23 04:39:29,343 INFO status has been updated to accepted\n2026-01-23 04:39:43,444 INFO status has been updated to running\n2026-01-23 04:41:26,402 INFO status has been updated to successful\nDownloading /scratch/cawohdcst_ft2/tyo/data/era5/era5_19950105/part2.grib\n2026-01-23 04:41:58,035 INFO Request ID is 3100a36b-00a4-448b-92f1-7cc208000079\n2026-01-23 04:41:59,125 INFO status has been updated to accepted\n2026-01-23 04:42:08,322 INFO status has been updated to running\n2026-01-23 04:43:54,771 INFO status has been updated to successful\n(cdsapi) sh-4.4$ \n</code></pre> <pre><code>2026-01-23 04:32:24,221 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-timeseries?tab=overview)\n2026-01-23 04:32:24,222 INFO Request ID is 13419524-b9d9-44e3-9f26-c285af4b614d\n2026-01-23 04:32:24,435 INFO status has been updated to accepted\n2026-01-23 04:34:19,878 INFO status has been updated to running\n2026-01-23 04:35:18,519 INFO status has been updated to successful\nDownloading /scratch/cawohdcst_ft2/tyo/data/era5/era5_19950105/part1.grib\n{'area': [15.5, 89.5, -15.5, 145.5],\n'data_format': 'grib',\n'day': '05',\n'month': '01',\n'product_type': 'reanalysis',\n'time': ['12:00',\n        '13:00',\n        '14:00',\n        '15:00',\n        '16:00',\n        '17:00',\n        '18:00',\n        '19:00',\n        '20:00',\n        '21:00',\n        '22:00',\n        '23:00'],\n'variable': ['10m_u_component_of_wind',\n            '10m_v_component_of_wind',\n            '2m_dewpoint_temperature',\n            '2m_temperature',\n            'mean_sea_level_pressure',\n            'sea_surface_temperature',\n            'surface_pressure',\n            'skin_temperature',\n            'snow_density',\n            'snow_depth',\n            'soil_temperature_level_1',\n            'soil_temperature_level_2',\n            'soil_temperature_level_3',\n            'soil_temperature_level_4',\n            'volumetric_soil_water_layer_1',\n            'volumetric_soil_water_layer_2',\n            'volumetric_soil_water_layer_3',\n            'volumetric_soil_water_layer_4',\n            'land_sea_mask',\n            'sea_ice_cover'],\n'year': '1995'}\n2026-01-23 04:35:27,043 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-timeseries?tab=overview)\n2026-01-23 04:35:27,043 INFO Request ID is cd9fb5f3-f0f3-4250-bf0f-b5bd34000543\n2026-01-23 04:35:27,242 INFO status has been updated to accepted\n2026-01-23 04:36:43,896 INFO status has been updated to running\n2026-01-23 04:37:24,808 INFO status has been updated to successful\nDownloading /scratch/cawohdcst_ft2/tyo/data/era5/era5_19950105/part2.grib\n2026-01-23 04:37:31,744 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-timeseries?tab=overview)\n2026-01-23 04:37:31,744 INFO Request ID is 6b0e3600-79b6-48aa-9f7f-f4bad9f0e8b9\n2026-01-23 04:37:31,929 INFO status has been updated to accepted\n2026-01-23 04:38:48,581 INFO status has been updated to running\n2026-01-23 04:39:27,245 INFO status has been updated to successful\n(cdsapi) [cawohdcst_ft2@mdclogin1 preprocess]$\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#era5-waves-data","level":3,"title":"ERA5 Waves Data","text":"<p>From the ERA5, the following variables are used as SWAN boundary conditions and need to be downloaded:</p> <ul> <li><code>significant_height_of_combined_wind_waves_and_swell</code>;</li> <li><code>mean_wave_period</code>;</li> <li><code>mean_wave_direction</code>;</li> </ul> <p>The data from ERA5 are downloaded using the ECMWF CDS api and python script. The script is located in <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/get_era5/get_era5_waves.py</code>. It should already placed in your working directory as we perform recursive copy in the ERA5 Atmosphere.</p> <p>Similar with the previous script (Code block 1), adjust the dates by replacing the value of variables <code>start_date</code> and <code>end_date</code> to specify the downloading period, as well as the <code>folder_name</code>. </p> <p>The <code>*.grib</code> files are from the day represented in the folder names starting at 12h00 UTC until the next day 12h00 UTC.</p> Click here to view the execution log. <pre><code>2026-01-23 04:37:29,540 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-timeseries?tab=overview)\n2026-01-23 04:37:29,541 INFO Request ID is 99f6fc34-1490-42d8-b873-00b15a9ddfed\n2026-01-23 04:37:29,726 INFO status has been updated to accepted\n2026-01-23 04:38:46,438 INFO status has been updated to successful\nDownloading /scratch/cawohdcst_ft2/tyo/data/era5_waves/era5_19950105/part1.grib\n{'area': [15.5, 89.5, -15.5, 145.5],\n'data_format': 'grib',\n'day': '05',\n'month': '01',\n'product_type': 'reanalysis',\n'time': ['12:00',\n        '13:00',\n        '14:00',\n        '15:00',\n        '16:00',\n        '17:00',\n        '18:00',\n        '19:00',\n        '20:00',\n        '21:00',\n        '22:00',\n        '23:00'],\n'variable': ['significant_height_of_combined_wind_waves_and_swell',\n            'mean_wave_period',\n            'mean_wave_direction',\n            'wave_spectral_directional_width'],\n'year': '1995'}\n2026-01-23 04:38:49,652 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-timeseries?tab=overview)\n2026-01-23 04:38:49,653 INFO Request ID is 8ba0c4a6-cd59-4f12-a2cd-c0496bb938b8\n2026-01-23 04:38:49,839 INFO status has been updated to accepted\n2026-01-23 04:39:23,434 INFO status has been updated to running\n2026-01-23 04:39:40,736 INFO status has been updated to successful\nDownloading /scratch/cawohdcst_ft2/tyo/data/era5_waves/era5_19950105/part2.grib\n2026-01-23 04:39:43,730 INFO [2025-12-11T00:00:00] Please note that a dedicated catalogue entry for this dataset, post-processed and stored in Analysis Ready Cloud Optimized (ARCO) format (Zarr), is available for optimised time-series retrievals (i.e. for retrieving data from selected variables for a single point over an extended period of time in an efficient way). You can discover it [here](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-timeseries?tab=overview)\n2026-01-23 04:39:43,730 INFO Request ID is e2bf8015-d921-4474-bde4-f6449f5e3381\n2026-01-23 04:39:43,916 INFO status has been updated to accepted\n2026-01-23 04:41:01,360 INFO status has been updated to running\n2026-01-23 04:41:40,172 INFO status has been updated to successful\n(cdsapi) sh-4.4$ \n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#mercator-glorys12v1-data","level":3,"title":"Mercator GLORYS12V1 Data","text":"<p>From the Mercator Reanalysis GLORYS12V1 the following variables are used as ROMS initial, boundary conditions and climatology files and need to be downloaded:</p> <ul> <li><code>uo</code> – Eastward current velocities;</li> <li><code>vo</code> – Northward current valocities;</li> <li><code>thetao</code> – Sea water potential temperature;</li> <li><code>so</code> – Sea water salinity;</li> <li><code>zos</code> – Sea surface height above geoid;</li> </ul> <p>Data from GLORYS12V1 are downloaded using copernicusmarine api and python sripts. Data download scripts: </p> <ul> <li><code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/get_glorys/get_glorys_reanalysis.py</code> (1995 - 2021)</li> <li><code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/get_glorys/get_glorys_reanalysis_interim.py</code> (2021 - 2024)</li> </ul> <p>Copy those scripts to your working directory. <pre><code>[cawohdcst_ft2@mdclogin1 preprocess]$ pwd\n/home/cawohdcst_ft2/tyo/preprocess\n[cawohdcst_ft2@mdclogin1 preprocess]$ cp -r /home/cawohdcst_ft2/hindcast_scripts/preprocess/get_glorys\n[cawohdcst_ft2@mdclogin1 preprocess]$ ls get_glorys/ -l\ntotal 8\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 1277 Jan 23 07:41 get_glorys_reanalysis_interim.py\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 1274 Jan 23 07:41 get_glorys_reanalysis.py\n[cawohdcst_ft2@mdclogin1 preprocess]$ \n</code></pre></p> <p>Similar with the previous script (Code block 1), adjust the dates by replacing the value of variables <code>start_date</code> and <code>end_date</code> to specify the downloading period, as well as the <code>output_directory</code>. </p> <p>The daily GLORYS12V1 files are placed on: <code>/scratch/&lt;your_user_name&gt;/&lt;your_name&gt;/data/mercator/GLORYS_Reanalysis_LO_YYYY-MM-DDT00:00:00.nc</code>, or in this case our username is <code>cawohdcst_ft2</code>.</p> Click here to view the execution log. <pre><code>INFO - 2026-01-23T04:35:10Z - Selected dataset version: \"202311\"\nINFO - 2026-01-23T04:35:10Z - Selected dataset part: \"default\"\nWARNING - 2026-01-23T04:35:10Z - Some of your subset selection [0.494, 5727.9169921875] for the depth dimension exceed the dataset coordinates [0.49402499198913574, 5727.9169921875]\nINFO - 2026-01-23T04:35:18Z - Starting download. Please wait...\n100%|██| 74/74 [00:19&lt;00:00,  3.74it/s]\nINFO - 2026-01-23T04:35:40Z - Successfully downloaded to /scratch/cawohdcst_ft2/tyo/data/mercator/GLORYS_Reanalysis_LO_1995-01-04T00:00:00.nc\nWARNING - 2026-01-23T04:35:40Z - 'force_download' has been deprecated.\nINFO - 2026-01-23T04:35:44Z - Selected dataset version: \"202311\"\nINFO - 2026-01-23T04:35:44Z - Selected dataset part: \"default\"\nWARNING - 2026-01-23T04:35:44Z - Some of your subset selection [0.494, 5727.9169921875] for the depth dimension exceed the dataset coordinates [0.49402499198913574, 5727.9169921875]\nINFO - 2026-01-23T04:35:52Z - Starting download. Please wait...\n100%|██| 74/74 [00:19&lt;00:00,  3.83it/s]\nINFO - 2026-01-23T04:36:13Z - Successfully downloaded to /scratch/cawohdcst_ft2/tyo/data/mercator/GLORYS_Reanalysis_LO_1995-01-05T00:00:00.nc\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#pre-processing","level":2,"title":"Pre Processing","text":"<p>After acquiring the global reanalysis data, it must be converted into the formats required by ROMS, SWAN, and WRF. The following sections describe the steps involved in transforming the data, as well as the locations of the scripts used in each stage. Once the pre-processing is complete, the data are properly formatted and ready to be consumed by the models.</p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#wrf-forcing-files","level":3,"title":"WRF Forcing Files","text":"<p>The regional atmospheric model WRF forcing files are generated using the WRF Preprocessing System (WPS) which is already installed on the HPC.</p> <p>After the ERA5 surface and pressure levels <code>.grib</code> files are downloaded for a given day, three sequential steps should be followed to generate the WRF file for that specific day:</p> <ul> <li>Run ungrib - <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/wps_run/slurm_run_ungrib.bash</code></li> <li>Run metgrid - <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/wps_run/slurm_run_ungrib.bash</code></li> <li>Run real - <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/wps_run/slurm_run_real.bash</code></li> </ul> <p>Now, copy these files to your working directory.  <pre><code>[cawohdcst_ft2@mdclogin1 preprocess]$ pwd\n/home/cawohdcst_ft2/tyo/preprocess\n[cawohdcst_ft2@mdclogin1 preprocess]$ cp -r /home/cawohdcst_ft2/hindcast_scripts/preprocess/wps_run\n[cawohdcst_ft2@mdclogin1 preprocess]$ ls wps_run/ -l\ntotal 12\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 2876 Jan 23 07:13 slurm_run_metgrid.bash\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 2892 Jan 23 07:13 slurm_run_real.bash\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 2793 Jan 23 07:56 slurm_run_ungrib.bash\n[cawohdcst_ft2@mdclogin1 preprocess]$ \n</code></pre> The codes should be run in sequence (step 1 – run ungrib, step 2 – run metgrid, step 3 – run real) for the dates you want to generate the forcing files.*</p> <p>Then run the slurm scripts with: <pre><code>sbatch slurm_run_ungrib.bash #(once completed, go to the next)\nsbatch slurm_run_metgrid.bash #(once completed, go to the next)\nsbatch slurm_run_real.bash #(once completed, WRF forcing file are generated)\n</code></pre></p> Click here to view the execution log. UngribMetgridReal run_ungrib_loop_.log<pre><code>...\n...\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n!  Successful completion of ungrib.   !\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nReading from FILE at time 1995-01-05_12\nReading from FILE at time 1995-01-05_15\nReading from FILE at time 1995-01-05_18\nReading from FILE at time 1995-01-05_21\nReading from FILE at time 1995-01-06_00\nReading from FILE at time 1995-01-06_03\nReading from FILE at time 1995-01-06_06\nReading from FILE at time 1995-01-06_09\n*** Successful completion of program avg_tsfc.exe ***\n</code></pre> run_metgrid_loop_.log<pre><code>+ mpiexec.hydra -bootstrap slurm -n 128 -ppn 32 ./metgrid.exe\nProcessing domain 1 of 1\n    ./TAVGSFC\nProcessing 1995-01-05_12\n    FILE_PL\n    FILE_SFC\nProcessing 1995-01-05_15\n    FILE_PL\n    FILE_SFC\nProcessing 1995-01-05_18\n    FILE_PL\n    FILE_SFC\nProcessing 1995-01-05_21\n    FILE_PL\n    FILE_SFC\nProcessing 1995-01-06_00\n    FILE_PL\n    FILE_SFC\nProcessing 1995-01-06_03\n    FILE_PL\n    FILE_SFC\nProcessing 1995-01-06_06\n    FILE_PL\n    FILE_SFC\nProcessing 1995-01-06_09\n    FILE_PL\n    FILE_SFC\nProcessing 1995-01-06_12\n    FILE_PL\n    FILE_SFC\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n!  Successful completion of metgrid.  !\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\nreal    2m57.264s\nuser    0m0.012s\nsys 0m0.040s\n++ date -d '19950105 +1 day' +%Y%m%d\n+ current_date=19950106\n+ [[ 19950106 -le 19950105 ]]\n</code></pre> run_real_loop_.log<pre><code>starting wrf task          256  of          512\nstarting wrf task          266  of          512\nstarting wrf task          269  of          512\nstarting wrf task          383  of          512\nstarting wrf task          265  of          512\nstarting wrf task          270  of          512\nstarting wrf task          377  of          512\nstarting wrf task          352  of          512\nstarting wrf task          261  of          512\nstarting wrf task          358  of          512\nstarting wrf task          373  of          512\nstarting wrf task          374  of          512\nstarting wrf task          263  of          512\nstarting wrf task          371  of          512\nstarting wrf task          375  of          512\nstarting wrf task          380  of          512\nstarting wrf task          304  of          512\nstarting wrf task          317  of          512\nstarting wrf task          318  of          512\n\nreal    4m53.225s\nuser    0m0.013s\nsys 0m0.041s\n++ date -d '19950105 +1 day' +%Y%m%d\n+ current_date=19950106\n+ [[ 19950106 -le 19950105 ]]\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#swan-forcing-files","level":3,"title":"SWAN Forcing Files","text":"<p>After the ERA5 waves <code>*.grib</code> files are downloaded for a desired range of dates the follow script should be edit to generate the SWAN boundary condition files: <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/get_swan_bry/make_swan_bc.py</code> and <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/get_swan_bry/slurm_make_swan_bc.bash</code></p> <p>Don't forget to copy this file to your working directory,  <pre><code>[cawohdcst_ft2@mdclogin1 preprocess]$ pwd\n/home/cawohdcst_ft2/tyo/preprocess\n[cawohdcst_ft2@mdclogin1 preprocess]$ cp -r /home/cawohdcst_ft2/hindcast_scripts/preprocess/get_swan_bry\n[cawohdcst_ft2@mdclogin1 preprocess]$ ls get_swan_bry/ -l\ntotal 8\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext 2874 Jan 23 07:41 make_swan_bc.py\n-rwxr-xr-x. 1 cawohdcst_ft2 cls_ext  279 Jan 23 07:41 slurm_make_swan_bc.bash\n[cawohdcst_ft2@mdclogin1 preprocess]$ \n</code></pre> and modify the following: make_swan_bc.py<pre><code>...\n...\n68 if __name__ == \"__main__\":\n69     start_str = \"1995-01-01\" # Modify this\n70     end_str = \"1995-01-06\"   # Modify this\n71     start_date = datetime.strptime(start_str, \"%Y-%m-%d\")\n72     end_date = datetime.strptime(end_str, \"%Y-%m-%d\")\n...\n...\n</code></pre></p> <p>Then run with the slurm script: <pre><code>sbatch slurm_make_swan_bc.bash\n</code></pre></p> Click here to view the execution log. run_swan_bc_.log<pre><code>...\n...\n✅ Processed era5_19950101\n✅ Processed era5_19950102\n✅ Processed era5_19950103\n✅ Processed era5_19950104\n✅ Processed era5_19950105\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#roms-forcing-files","level":3,"title":"ROMS Forcing Files","text":"<p>GLORYS12V1 daily data are preprocessed using modified scripts from the LiveOcean python toolbox. The toolbox is a set of tools developed for a forecast system in the US northwest coast.</p> <p>The LO pre-processing scripts are designed to generate ROMS forcing files from HYCOM forecast outputs. The scripts to generate ROMS initial conditions files were adapted to use GLORYS12V1 data and interpolation methods were also modified, changing the nearest neighbor interpolations on both horizontal and vertical to linear interpolation.</p> <p>The modified scripts are under the folder <code>/home/cawohdcst_ft2/hindcast_scripts/preprocess/LO_user</code>. Copy this directory to your working directory. <pre><code>[cawohdcst_ft2@mdclogin1 preprocess]$ pwd\n/home/cawohdcst_ft2/tyo/preprocess\n[cawohdcst_ft2@mdclogin1 preprocess]$ cp -r /home/cawohdcst_ft2/hindcast_scripts/preprocess/LO_user .\n[cawohdcst_ft2@mdclogin1 preprocess]$ ls LO_user/ -l\ntotal 28\ndrwxr-xr-x.  5 cawohdcst_ft2 cls_ext 4096 Jan 23 09:01 driver\ndrwxr-xr-x. 11 cawohdcst_ft2 cls_ext 4096 Jan 23 08:49 extract\ndrwxr-xr-x.  4 cawohdcst_ft2 cls_ext 4096 Jan 23 08:49 forcing\n-rwxr-xr-x.  1 cawohdcst_ft2 cls_ext 3564 Jan 23 08:58 get_lo_info.py\ndrwxr-xr-x.  3 cawohdcst_ft2 cls_ext 4096 Jan 23 08:49 lo_tools\ndrwxr-xr-x.  3 cawohdcst_ft2 cls_ext 4096 Jan 23 08:49 pgrid\ndrwxr-xr-x.  2 cawohdcst_ft2 cls_ext 4096 Jan 23 08:49 __pycache__\n[cawohdcst_ft2@mdclogin1 preprocess]$ \n</code></pre></p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#1-generate-templates-for-icbc","level":4,"title":"1 Generate templates for ic/bc","text":"<p>Generate template files for the hindcast using <code>/home/cawohdcst_ft2/tyo/preprocess/get_roms_icbc/slurm_run_ocnA0_wrap.bash</code>. Adjust the <code>date</code> as needed (see the hightlighted lines).</p> Click here to see the script slurm_run_ocnA0_wrap.bash<pre><code>#!/bin/bash\n#SBATCH --job-name=forcing_parallel\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=4     # number of parallel jobs allowed\n#SBATCH --time=01:00:00\n#SBATCH --partition=HDCAST\n#SBATCH --output=forcing_parallel_%j.out\n\nsource ~/.bashrc\nsource /home/cawohdcst_ft2/opt/miniforge3/etc/profile.d/conda.sh\nconda activate loenv\n\n# =========================\n# INIT DAY (new)\n# =========================\necho \"Running initialization day\"\npython driver_forcing3.py -g cawo -0 \"1995.01.01\" -s \"new\" -f ocnA0\n\n# =========================\n# DATE RANGE\n# =========================\nstart_date=\"1995-01-02\"\nend_date=\"1995-01-05\"\ncurrent_date=\"$start_date\"\nMAX_PARALLEL=16   # limit parallel processes\njob_count=0\necho \"Launching parallel forcing jobs...\"\nwhile [[ \"$(date -d \"$current_date\" +%s)\" -le \"$(date -d \"$end_date\" +%s)\" ]]\ndo\n    formatted_date=$(date -d \"$current_date\" +%Y.%m.%d)\n    echo \"Launching forcing for $formatted_date\"\n    python driver_forcing3.py -g cawo -0 \"$formatted_date\" -f ocnA0 &amp;\n    ((job_count++))\n    # limit parallel jobs\n    if (( job_count &gt;= MAX_PARALLEL )); then\n        wait   # wait for all background jobs\n        job_count=0\n    fi\n    current_date=$(date -d \"$current_date + 1 day\" +%Y-%m-%d)\ndone\n# wait for remaining jobs\nwait\necho \"All forcing jobs completed.\"\n</code></pre> <p>Launch the script. <pre><code>sbatch slurm_run_ocnA0_wrap.bash\n</code></pre></p> <p>The script generates ic/bc for ROMS stored in the following directory pattern <code>/scratch/cawohdcst_ft2/data/roms_forcing/fYYYYMMDD/ocnA0/</code>. Noted that the day 1 also consists <code>ocean_ini.nc</code> file as an initial conditions. <pre><code>[cawohdcst_ft2@mdclogin1 get_roms_icbc]$ ls /scratch/cawohdcst_ft2/data/roms_forcing/f19950101/ocnA0/ -lth\ntotal 252M\n-rw-r--r--. 1 cawohdcst_ft2 cls_ext 262K Jan 23 16:01 ocean_bry.nc\n-rw-r--r--. 1 cawohdcst_ft2 cls_ext 126M Jan 23 16:01 ocean_ini.nc\n-rw-r--r--. 1 cawohdcst_ft2 cls_ext 126M Jan 23 16:00 ocean_clm.nc\ndrwxrwxr-x. 2 cawohdcst_ft2 cls_ext 4.0K Dec 15 19:22 Data\ndrwxrwxr-x. 2 cawohdcst_ft2 cls_ext 4.0K Dec 15 19:22 Info\n(loenv) [cawohdcst_ft2@mdclogin1 get_roms_icbc]$ ls /scratch/cawohdcst_ft2/data/roms_forcing/f19950102/ocnA0/ -lth\ntotal 126M\n-rw-r--r--. 1 cawohdcst_ft2 cls_ext 262K Jan 23 16:02 ocean_bry.nc\n-rw-r--r--. 1 cawohdcst_ft2 cls_ext 126M Jan 23 16:02 ocean_clm.nc\ndrwxr-xr-x. 2 cawohdcst_ft2 cls_ext 4.0K Dec 16 13:29 Data\ndrwxr-xr-x. 2 cawohdcst_ft2 cls_ext 4.0K Dec 16 13:29 Info\n</code></pre></p> Click here to view the execution log. log_ocnA0_.log<pre><code>Running initialization day\ndt0, dt1 1995-01-01 00:00:00 1995-01-01 00:00:00\n------Forcing: ocnA0, backfill, 1995.01.01-1995.01.01 ------\n* frc=ocnA0, day=1995.01.01, result=success, note=NONE\nstart=2026.01.23 10:30:23 (took 360 sec)\n/home/cawohdcst_ft2/LO_output/forcing/cawo/f1995.01.01/ocnA0\n\nLaunching parallel forcing jobs...\nLaunching forcing for 1995.01.02\nLaunching forcing for 1995.01.03\nLaunching forcing for 1995.01.04\nLaunching forcing for 1995.01.05\ndt0, dt1 1995-01-03 00:00:00 1995-01-03 00:00:00\n------Forcing: ocnA0, backfill, 1995.01.03-1995.01.03 ------\n* frc=ocnA0, day=1995.01.03, result=success, note=NONE\nstart=2026.01.23 10:36:30 (took 129 sec)\n/home/cawohdcst_ft2/LO_output/forcing/cawo/f1995.01.03/ocnA0\n\ndt0, dt1 1995-01-05 00:00:00 1995-01-05 00:00:00\n------Forcing: ocnA0, backfill, 1995.01.05-1995.01.05 ------\n* frc=ocnA0, day=1995.01.05, result=success, note=NONE\nstart=2026.01.23 10:36:30 (took 130 sec)\n/home/cawohdcst_ft2/LO_output/forcing/cawo/f1995.01.05/ocnA0\n\ndt0, dt1 1995-01-02 00:00:00 1995-01-02 00:00:00\n------Forcing: ocnA0, backfill, 1995.01.02-1995.01.02 ------\n* frc=ocnA0, day=1995.01.02, result=success, note=NONE\nstart=2026.01.23 10:36:30 (took 130 sec)\n/home/cawohdcst_ft2/LO_output/forcing/cawo/f1995.01.02/ocnA0\n\ndt0, dt1 1995-01-04 00:00:00 1995-01-04 00:00:00\n------Forcing: ocnA0, backfill, 1995.01.04-1995.01.04 ------\n* frc=ocnA0, day=1995.01.04, result=success, note=NONE\nstart=2026.01.23 10:36:30 (took 131 sec)\n/home/cawohdcst_ft2/LO_output/forcing/cawo/f1995.01.04/ocnA0\n\nAll forcing jobs completed.\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#2-populate-templates-for-icbc","level":4,"title":"2 Populate templates for ic/bc","text":"<p><code>/home/cawohdcst_ft2/tyo/preprocess/get_roms_icbc/slurm_run_ocnGcawo_parallel_v3.bash</code> – driver script for generating the ROMS forcing files;</p> <p>Launch the script. <pre><code>sbatch slurm_run_ocnGcawo_parallel_v3.bash\n</code></pre> <pre><code>[cawohdcst_ft2@mdclogin1 get_roms_icbc]$ ls /scratch/cawohdcst_ft2/data/roms_forcing/f19950101/ocnG/ -lth\ntotal 6.3G\n-rwxrwxr-x. 1 cawohdcst_ft2 cls_ext 8.8M Jan 23 16:53 ocean_bry.nc\n-rwxrwxr-x. 1 cawohdcst_ft2 cls_ext 3.2G Jan 23 16:53 ocean_clm.nc\n-rwxrwxr-x. 1 cawohdcst_ft2 cls_ext 3.2G Dec 16 09:04 ocean_ini.nc\n[cawohdcst_ft2@mdclogin1 get_roms_icbc]$ ls /scratch/cawohdcst_ft2/data/roms_forcing/f19950102/ocnG/ -lth\ntotal 3.2G\n-rw-r--r--. 1 cawohdcst_ft2 cls_ext 8.8M Jan 23 16:53 ocean_bry.nc\n-rw-r--r--. 1 cawohdcst_ft2 cls_ext 3.2G Jan 23 16:53 ocean_clm.nc\n[cawohdcst_ft2@mdclogin1 get_roms_icbc]$ \n</code></pre></p> Click here to view the execution log. <pre><code>...\n...\n...\n47\n48\n49\nVertical interpolation\nVertical interpolation\nVertical interpolation\nVertical interpolation\nFinished 1995-01-01\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#running-the-hindcast","level":2,"title":"Running the Hindcast","text":"<p>Once the data are properly pre-processed for the selected period, we are ready to run the hindcast. This section describes the steps required to compile the model, prepare the input folders (grid, configuration files, and forcing files), and set up the output directories. After completing these steps, the model can be executed and the results will be available for the post-processing stage.</p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#compiling-coawst","level":3,"title":"Compiling COAWST","text":"<p>The model code used to run the hindcast is placed at:</p> <ul> <li><code>/home/cawohdcst_ft2/models/cawo_3way_swell_mods_ramp_tides/</code> for day 1 </li> <li><code>/home/cawohdcst_ft2/models/cawo_3way_swell_mods_no_ramp_tides/</code> for after day 1</li> </ul> <p>There are some varibles need to be changed related to the path inside <code>coawst.bash</code>. Additionally, the different configurations on the ramp tides usage is adjusted in the <code>Projects/CAWO_3way/cawo_3way.h</code>. But, in this case, you don't need to worry as it has been done during the FT. So, all you need to do is to compile the Coawst model for each scenario to get the binary <code>coawstM</code>. Here is the command to compile the model.</p> <pre><code>sbatch slurm_compile_cawo.bash\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#running-scheme","level":3,"title":"Running Scheme","text":"<p>The runs are being conducted at your designed directory which defined in <code>env.sh</code>. In this example, they're located at <code>/scratch/cawohdcst_ft2/tyo/cawo_hindcast/cawo_hindcast_run</code> and its outputs are directed to <code>/scratch/cawohdcst_ft2/tyo/cawo_hindcast/cawo_output</code>. </p> <p>However, the working directory where we launch the source code still from <code>home</code> directory, e.g. <code>/home/cawohdcst_ft2/tyo/hindcast_run</code>. The <code>scratch</code> folder is used for I/O purposes.</p> <p>The hindcast is run in separate daily cycles. A folder for each cycle should be created by using the follwing script: <pre><code>python create_folders.py\n</code></pre></p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#modifying-namelist-files","level":3,"title":"Modifying Namelist Files","text":"<p>The following scripts will modify the namelist files required by the three models according to each daily cycle/run directory. To modify the namelist files according to the respective days run:</p> <p>Modifying day1 <pre><code>(base) sh-4.4$ python modify_dot_in.py 19950101  19950101 --day1\nStart date: 19950101\nEnd date  : 19950101\nDay1 mode : True\nModels   : roms, swan, wrf\n--------------------------------------------------\n=== Modifying ROMS input files ===\n=== Modifying SWAN input files ===\n=== Modifying WRF input files ===\n\nAll .in files updated successfully.\n</code></pre></p> <p>Non day1 <pre><code>(base) sh-4.4$ python modify_dot_in.py 19950102 19950105\nStart date: 19950102\nEnd date  : 19950105\nDay1 mode : False\nModels   : roms, swan, wrf\n--------------------------------------------------\n=== Modifying ROMS input files ===\n=== Modifying SWAN input files ===\n=== Modifying WRF input files ===\n\nAll .in files updated successfully.\n</code></pre></p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#copying-input-files","level":3,"title":"Copying input files","text":"<p>The following script will copy the files that are needed into the daily run directories. These files include the WRF forcing files generated with WPS, coawstM executable, slurm script and others. </p> <pre><code>./copy_files_for_run_day1.bash # for day1\n./copy_files_for_run.bash # after day1\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#running-a-day-cycle","level":3,"title":"Running a day cycle","text":"<p>The hindcast is designed to run in daily cycles, at first it is recommended that at least two or three days be run individually. This helps the user to better understand the sequence before launching the automation script.  Enter your <code>scratch</code> directory for the day you want to run and run the following slurm script:</p> <pre><code>sbatch slurm_run_cawo_3way_hdcst.bash\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#running-automation","level":3,"title":"Running automation","text":"<p>As the 30 years hindcast is split into daily cycles, a driver script was designed to launch the sequential daily runs one after another. The bash script goes from a given start day to an end day. As a daily cycle is complete, the script advances to the next day and continues to do it until the final day is reached. To automatically run a sequence of days, run the following:</p> <pre><code>nohup ./run_hindcast.bash &amp;&gt; log/log_run.log &amp;\n</code></pre>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#post-processing","level":2,"title":"Post Processing","text":"<p>The raw outputs from WRF (surface and pressure levels) and ROMS/SWAN should be postprocessed to meet the clients requirements. The data needs to be CF compliant and store only the variables needed for surface (WRF 2D), pressure levels (WRF 3D), surface (ocean 2D), and z levels (ocean 3D).</p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#wrf2d","level":3,"title":"WRF2D","text":"<p>The raw outputs from WRF are remapped to the required regularly spaced latitude and longitude grid using the <code>xesmf</code> toolbox. The /home/cawohdcst/postprocess directory should be mirrored on your home directory:</p> <pre><code>cp –r /scratch/cawohdcst_ft/home/cawohdcst/postprocess ~/\n</code></pre> <p>Then edit and run the script below: <pre><code>sbatch ~/postprocess/slurm_run_post_wrf2d.bash\n</code></pre></p> <p>*Remember to adjust the paths related to your user and to choose the start and end dates for postprocessing. The postprocessed files will be placed on: <code>/scratch/&lt;your_user_name&gt;/data/postprocessed/wrf2d/fyyyymmdd</code></p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#wrf3d","level":3,"title":"WRF3D","text":"<p>Similarly to the WRF 2D, run the script bellow:</p> <pre><code>sbatch ~/postprocess/slurm_run_post_wrf3d.bash\n</code></pre> <p>The postprocessed files will be placed on: <code>/scratch/&lt;your_user_name&gt;/data/postprocessed/wrf3d/fyyyymmdd</code></p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#ocean2d","level":3,"title":"Ocean2D","text":"<p>Run:  <pre><code>sbatch ~/postprocess/slurm_run_post_ocean2d.bash\n</code></pre> The postprocessed files will be placed on: <code>/scratch/&lt;your_user_name&gt;/data/postprocessed/ocean2d/fyyyymmdd</code></p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#ocean3d","level":3,"title":"Ocean3D","text":"<p>Additionally to the <code>xesmf</code> remapping, the sigma layer outputs should be converted to z levels. For that task, the <code>xroms</code> package is used. Run:  <pre><code>sbatch ~/postprocess/slurm_run_post_ocean3d.bash\n</code></pre> The postprocessed files will be placed on: <code>/scratch/&lt;your_user_name&gt;/data/postprocessed/ocean3d/fyyyymmdd</code> </p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/hindcast/#summary-and-common-problems","level":2,"title":"Summary and Common Problems","text":"<p>work in progres</p>","path":["InaCAWO","Tutorial","Hindcast Mode"],"tags":[]},{"location":"inacawo/tutorial/install/","level":1,"title":"Installation","text":"<p>work in progress</p>","path":["Installation"],"tags":[]},{"location":"zensical/","level":1,"title":"Get started","text":"<p>For full documentation visit zensical.org.</p>","path":["Get started"],"tags":[]},{"location":"zensical/#commands","level":2,"title":"Commands","text":"<ul> <li><code>zensical new</code> - Create a new project</li> <li><code>zensical serve</code> - Start local web server</li> <li><code>zensical build</code> - Build your site</li> </ul>","path":["Get started"],"tags":[]},{"location":"zensical/#examples","level":2,"title":"Examples","text":"","path":["Get started"],"tags":[]},{"location":"zensical/#admonitions","level":3,"title":"Admonitions","text":"<p>Go to documentation</p> <p>Note</p> <p>This is a note admonition. Use it to provide helpful information.</p> <p>Warning</p> <p>This is a warning admonition. Be careful!</p>","path":["Get started"],"tags":[]},{"location":"zensical/#details","level":3,"title":"Details","text":"<p>Go to documentation</p> Click to expand for more info <p>This content is hidden until you click to expand it. Great for FAQs or long explanations.</p>","path":["Get started"],"tags":[]},{"location":"zensical/#code-blocks","level":2,"title":"Code Blocks","text":"<p>Go to documentation</p> Code blocks<pre><code>def greet(name):\n    print(f\"Hello, {name}!\") # (1)!\n\ngreet(\"Python\")\n</code></pre> <ol> <li> <p>Go to documentation</p> <p>Code annotations allow to attach notes to lines of code.</p> </li> </ol> <p>Code can also be highlighted inline: <code>print(\"Hello, Python!\")</code>.</p>","path":["Get started"],"tags":[]},{"location":"zensical/#content-tabs","level":2,"title":"Content tabs","text":"<p>Go to documentation</p> PythonRust <pre><code>print(\"Hello from Python!\")\n</code></pre> <pre><code>println!(\"Hello from Rust!\");\n</code></pre>","path":["Get started"],"tags":[]},{"location":"zensical/#diagrams","level":2,"title":"Diagrams","text":"<p>Go to documentation</p> <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>","path":["Get started"],"tags":[]},{"location":"zensical/#footnotes","level":2,"title":"Footnotes","text":"<p>Go to documentation</p> <p>Here's a sentence with a footnote.<sup>1</sup></p> <p>Hover it, to see a tooltip.</p>","path":["Get started"],"tags":[]},{"location":"zensical/#formatting","level":2,"title":"Formatting","text":"<p>Go to documentation</p> <ul> <li>This was marked (highlight)</li> <li>This was inserted (underline)</li> <li>This was deleted (strikethrough)</li> <li>H<sub>2</sub>O</li> <li>A<sup>T</sup>A</li> <li>Ctrl+Alt+Del</li> </ul>","path":["Get started"],"tags":[]},{"location":"zensical/#icons-emojis","level":2,"title":"Icons, Emojis","text":"<p>Go to documentation</p> <ul> <li> <code>:sparkles:</code></li> <li> <code>:rocket:</code></li> <li> <code>:tada:</code></li> <li> <code>:memo:</code></li> <li> <code>:eyes:</code></li> </ul>","path":["Get started"],"tags":[]},{"location":"zensical/#maths","level":2,"title":"Maths","text":"<p>Go to documentation</p> \\[ \\cos x=\\sum_{k=0}^{\\infty}\\frac{(-1)^k}{(2k)!}x^{2k} \\] <p>Needs configuration</p> <p>Note that MathJax is included via a <code>script</code> tag on this page and is not configured in the generated default configuration to avoid including it in a pages that do not need it. See the documentation for details on how to configure it on all your pages if they are more Maths-heavy than these simple starter pages.</p>","path":["Get started"],"tags":[]},{"location":"zensical/#task-lists","level":2,"title":"Task Lists","text":"<p>Go to documentation</p> <ul> <li> Install Zensical</li> <li> Configure <code>zensical.toml</code></li> <li> Write amazing documentation</li> <li> Deploy anywhere</li> </ul>","path":["Get started"],"tags":[]},{"location":"zensical/#tooltips","level":2,"title":"Tooltips","text":"<p>Go to documentation</p> <p>Hover me</p> <ol> <li> <p>This is the footnote. ↩</p> </li> </ol>","path":["Get started"],"tags":[]},{"location":"zensical/markdown/","level":1,"title":"Markdown in 5min","text":"","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#headers","level":2,"title":"Headers","text":"<pre><code># H1 Header\n## H2 Header\n### H3 Header\n#### H4 Header\n##### H5 Header\n###### H6 Header\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#text-formatting","level":2,"title":"Text formatting","text":"<pre><code>**bold text**\n*italic text*\n***bold and italic***\n~~strikethrough~~\n`inline code`\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#links-and-images","level":2,"title":"Links and images","text":"<pre><code>[Link text](https://example.com)\n[Link with title](https://example.com \"Hover title\")\n![Alt text](image.jpg)\n![Image with title](image.jpg \"Image title\")\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#lists","level":2,"title":"Lists","text":"<pre><code>Unordered:\n- Item 1\n- Item 2\n  - Nested item\n\nOrdered:\n1. First item\n2. Second item\n3. Third item\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#blockquotes","level":2,"title":"Blockquotes","text":"<pre><code>&gt; This is a blockquote\n&gt; Multiple lines\n&gt;&gt; Nested quote\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#code-blocks","level":2,"title":"Code blocks","text":"<pre><code>```javascript\nfunction hello() {\n  console.log(\"Hello, world!\");\n}\n```\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#tables","level":2,"title":"Tables","text":"<pre><code>| Header 1 | Header 2 | Header 3 |\n|----------|----------|----------|\n| Row 1    | Data     | Data     |\n| Row 2    | Data     | Data     |\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#horizontal-rule","level":2,"title":"Horizontal rule","text":"<pre><code>---\nor\n***\nor\n___\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#task-lists","level":2,"title":"Task lists","text":"<pre><code>- [x] Completed task\n- [ ] Incomplete task\n- [ ] Another task\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#escaping-characters","level":2,"title":"Escaping characters","text":"<pre><code>Use backslash to escape: \\* \\_ \\# \\`\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"zensical/markdown/#line-breaks","level":2,"title":"Line breaks","text":"<pre><code>End a line with two spaces  \nto create a line break.\n\nOr use a blank line for a new paragraph.\n</code></pre>","path":["Markdown in 5min"],"tags":[]}]}